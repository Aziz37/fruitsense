{"cells":[{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3615,"status":"ok","timestamp":1719849336505,"user":{"displayName":"Patrick Do","userId":"05067780781205823530"},"user_tz":240},"id":"ULFjPC11ebqW","outputId":"fe1691f3-effa-488b-aebb-ba0635200972"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1719849336506,"user":{"displayName":"Patrick Do","userId":"05067780781205823530"},"user_tz":240},"id":"3WX5Z_WuefB3","outputId":"99204444-3712-407a-b716-91618a06d8ca"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1bNsY41NQ7yt_0gKqP3j-2gJ1pdli4usp/Fruit_States_RnC\n"]}],"source":["%cd '/content/drive/My Drive/Fruit_States_RnC'"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1719849336506,"user":{"displayName":"Patrick Do","userId":"05067780781205823530"},"user_tz":240},"id":"R3L9-SE3ehJz"},"outputs":[],"source":["import argparse\n","import os\n","import sys\n","import logging\n","import torch\n","import time\n","from model_fruits import Encoder, model_dict\n","from dataset_fruits import *\n","from utils_fruits import *\n","\n","print = logging.info"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1719849336506,"user":{"displayName":"Patrick Do","userId":"05067780781205823530"},"user_tz":240},"id":"wPs5VQUyeviw"},"outputs":[],"source":["def parse_option(args=None):\n","    parser = argparse.ArgumentParser('argument for training')\n","\n","    parser.add_argument('--print_freq', type=int, default=10, help='print frequency')\n","    parser.add_argument('--save_freq', type=int, default=50, help='save frequency')\n","\n","    parser.add_argument('--batch_size', type=int, default=256, help='batch_size')\n","    parser.add_argument('--num_workers', type=int, default=16, help='num of workers to use')\n","    parser.add_argument('--epochs', type=int, default=200, help='number of training epochs')\n","    parser.add_argument('--learning_rate', type=float, default=0.001, help='learning rate')\n","    parser.add_argument('--lr_decay_rate', type=float, default=0.8, help='decay rate for learning rate')\n","    parser.add_argument('--weight_decay', type=float, default=0, help='weight decay')\n","    parser.add_argument('--momentum', type=float, default=0.9, help='momentum')\n","    parser.add_argument('--trial', type=str, default='0', help='id for recording multiple runs')\n","\n","    parser.add_argument('--data_folder', type=str, default='./data_fruits', help='path to custom dataset')\n","    parser.add_argument('--dataset', type=str, default='FruitsDataset', choices=['FruitsDataset', 'FruitsDatasetV2', 'FruitsDatasetRGB', 'FruitsDataset30C'], help='dataset')\n","    parser.add_argument('--model', type=str, default='resnet18', choices=['resnet18', 'resnet50'])\n","    parser.add_argument('--resume', type=str, default='', help='resume ckpt path')\n","    parser.add_argument('--aug', type=str, default='crop,flip,color,grayscale,rotate', help='augmentations')\n","\n","    parser.add_argument('--ckpt', type=str, default='save/FruitsDataset_models/RnC_FruitsDataset_resnet18_ep_400_lr_0.5_d_0.1_wd_0.0001_mmt_0.9_bsz_256_aug_crop,flip,rotate_temp_2_label_l1_feature_l2_trial_0/last.pth', help='path to the trained encoder')\n","\n","    if args is None:\n","        args = []\n","    opt = parser.parse_args(args=args)\n","\n","    opt.model_name = 'Regressor_{}_ep_{}_lr_{}_d_{}_wd_{}_mmt_{}_bsz_{}_trial_{}'. \\\n","        format(opt.dataset, opt.epochs, opt.learning_rate, opt.lr_decay_rate,\n","               opt.weight_decay, opt.momentum, opt.batch_size, opt.trial)\n","    if len(opt.resume):\n","        opt.model_name = opt.resume.split('/')[-1][:-len('_last.pth')]\n","    opt.save_folder = '/'.join(opt.ckpt.split('/')[:-1])\n","\n","    logging.root.handlers = []\n","    logging.basicConfig(\n","        level=logging.INFO,\n","        format=\"%(asctime)s | %(message)s\",\n","        handlers=[\n","            logging.FileHandler(os.path.join(opt.save_folder, f'{opt.model_name}.log')),\n","            logging.StreamHandler()\n","        ]\n","    )\n","\n","    print(f\"Model name: {opt.model_name}\")\n","    print(f\"Options: {opt}\")\n","\n","    return opt"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1719849336506,"user":{"displayName":"Patrick Do","userId":"05067780781205823530"},"user_tz":240},"id":"BsPxqLQ4eQKV"},"outputs":[],"source":["def set_loader(opt, num_channel=3):\n","    train_transform = get_transforms(split='train', aug=opt.aug, num_channel=num_channel)\n","    val_transform = get_transforms(split='val', aug=opt.aug, num_channel=num_channel)\n","    print(f\"Train Transforms: {train_transform}\")\n","    print(f\"Val Transforms: {val_transform}\")\n","\n","    train_dataset = globals()[opt.dataset](\n","        data_folder=opt.data_folder,\n","        transform=train_transform,\n","        split='train'\n","    )\n","    val_dataset = globals()[opt.dataset](\n","        data_folder=opt.data_folder,\n","        transform=val_transform,\n","        split='val'\n","    )\n","    test_dataset = globals()[opt.dataset](\n","        data_folder=opt.data_folder,\n","        transform=val_transform,\n","        split='test'\n","    )\n","    # full_dataset = globals()[opt.dataset](\n","    #     data_folder=opt.data_folder,\n","    #     transform=val_transform,\n","    #     split='full'\n","    # )\n","\n","    print(f'Train set size: {train_dataset.__len__()}\\t'\n","          f'Val set size: {val_dataset.__len__()}\\t'\n","          f'Test set size: {test_dataset.__len__()}')\n","\n","    train_loader = torch.utils.data.DataLoader(\n","        train_dataset, batch_size=opt.batch_size, shuffle=True, num_workers=opt.num_workers, pin_memory=True\n","    )\n","    val_loader = torch.utils.data.DataLoader(\n","        val_dataset, batch_size=opt.batch_size, shuffle=False, num_workers=opt.num_workers, pin_memory=True\n","    )\n","    test_loader = torch.utils.data.DataLoader(\n","        test_dataset, batch_size=opt.batch_size, shuffle=False, num_workers=opt.num_workers, pin_memory=True\n","    )\n","    # full_loader = torch.utils.data.DataLoader(\n","    #     full_dataset, batch_size=opt.batch_size, shuffle=False, num_workers=opt.num_workers, pin_memory=True\n","    # )\n","\n","    # return train_loader, val_loader, test_loader, full_loader\n","    return train_loader, val_loader, test_loader\n","\n","\n","def set_model(opt, num_channel=3):\n","    model = Encoder(name=opt.model, in_channel=num_channel)\n","    criterion = torch.nn.L1Loss()\n","\n","    dim_in = model_dict[opt.model][1]\n","    dim_out = get_label_dim(opt.dataset)\n","    regressor = torch.nn.Linear(dim_in, dim_out)\n","    ckpt = torch.load(opt.ckpt, map_location='cpu')\n","    state_dict = ckpt['model']\n","\n","    if torch.cuda.device_count() > 1:\n","        model.encoder = torch.nn.DataParallel(model.encoder)\n","    else:\n","        new_state_dict = {}\n","        for k, v in state_dict.items():\n","            k = k.replace(\"module.\", \"\")\n","            new_state_dict[k] = v\n","        state_dict = new_state_dict\n","    model = model.cuda()\n","    regressor = regressor.cuda()\n","    criterion = criterion.cuda()\n","    torch.backends.cudnn.benchmark = True\n","\n","    model.load_state_dict(state_dict)\n","    print(f\"<=== Epoch [{ckpt['epoch']}] checkpoint Loaded from {opt.ckpt}!\")\n","\n","    return model, regressor, criterion\n","\n","\n","def train(train_loader, model, regressor, criterion, optimizer, epoch, opt):\n","    model.eval()\n","    regressor.train()\n","\n","    batch_time = AverageMeter()\n","    data_time = AverageMeter()\n","    losses = AverageMeter()\n","\n","    end = time.time()\n","    for idx, (images, labels) in enumerate(train_loader):\n","        data_time.update(time.time() - end)\n","\n","        images = images.cuda(non_blocking=True)\n","        labels = labels.cuda(non_blocking=True)\n","        bsz = labels.shape[0]\n","\n","        with torch.no_grad():\n","            features = model(images)\n","\n","        output = regressor(features.detach())\n","        loss = criterion(output, labels)\n","        losses.update(loss.item(), bsz)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","\n","        if (idx + 1) % opt.print_freq == 0:\n","            print('Train: [{0}][{1}/{2}]\\t'\n","                  'BT {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n","                  'DT {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n","                  'loss {loss.val:.3f} ({loss.avg:.3f})'.format(\n","                epoch, idx + 1, len(train_loader), batch_time=batch_time,\n","                data_time=data_time, loss=losses))\n","            sys.stdout.flush()\n","\n","\n","def validate(val_loader, model, regressor):\n","    model.eval()\n","    regressor.eval()\n","\n","    losses = AverageMeter()\n","    criterion_l1 = torch.nn.L1Loss()\n","\n","    with torch.no_grad():\n","        for idx, (images, labels) in enumerate(val_loader):\n","            images = images.cuda()\n","            labels = labels.cuda()\n","            bsz = labels.shape[0]\n","\n","            features = model(images)\n","            output = regressor(features)\n","\n","            loss_l1 = criterion_l1(output, labels)\n","            losses.update(loss_l1.item(), bsz)\n","\n","    return losses.avg\n","\n","def validate_modified(loader, model, regressor, split=''):\n","  model.eval()\n","  regressor.eval()\n","\n","  losses = AverageMeter()\n","  criterion_l1 = torch.nn.L1Loss()\n","  all_outputs = []\n","\n","  with torch.no_grad():\n","      for idx, (images, labels) in enumerate(loader):\n","          images = images.cuda()\n","          labels = labels.cuda()\n","          bsz = labels.shape[0]\n","\n","          features = model(images)\n","          output = regressor(features)\n","\n","          all_outputs.append(output.detach().cpu().numpy())\n","\n","          loss_l1 = criterion_l1(output, labels)\n","          losses.update(loss_l1.item(), bsz)\n","\n","  all_outputs = np.concatenate(all_outputs, axis=0)\n","  np.save('outputs/predicted_y_' + split + '.npy', all_outputs)\n","\n","  return losses.avg\n","\n","def main_linear(args=None, num_channel=3):\n","  opt = parse_option(args)\n","\n","  # build data loader\n","  # train_loader, val_loader, test_loader, full_loader = set_loader(opt)\n","  train_loader, val_loader, test_loader = set_loader(opt, num_channel=num_channel)\n","\n","  # build model and criterion\n","  model, regressor, criterion = set_model(opt, num_channel=num_channel)\n","\n","  # build optimizer\n","  optimizer = set_optimizer(opt, regressor)\n","\n","  save_file_best = os.path.join(opt.save_folder, f\"{opt.model_name}_best.pth\")\n","  save_file_last = os.path.join(opt.save_folder, f\"{opt.model_name}_last.pth\")\n","  best_error = 1e5\n","\n","  start_epoch = 1\n","  if len(opt.resume):\n","      ckpt_state = torch.load(opt.resume)\n","      regressor.load_state_dict(ckpt_state['state_dict'])\n","      start_epoch = ckpt_state['epoch'] + 1\n","      best_error = ckpt_state['best_error']\n","      print(f\"<=== Epoch [{ckpt_state['epoch']}] Resumed from {opt.resume}!\")\n","\n","\n","  # training routine\n","  for epoch in range(start_epoch, opt.epochs + 1):\n","      adjust_learning_rate(opt, optimizer, epoch)\n","\n","      # train for one epoch\n","      train(train_loader, model, regressor, criterion, optimizer, epoch, opt)\n","\n","      valid_error = validate(val_loader, model, regressor)\n","      print('Val L1 error: {:.3f}'.format(valid_error))\n","\n","      is_best = valid_error < best_error\n","      best_error = min(valid_error, best_error)\n","      print(f\"Best Error: {best_error:.3f}\")\n","\n","      if is_best:\n","          torch.save({\n","              'epoch': epoch,\n","              'state_dict': regressor.state_dict(),\n","              'best_error': best_error\n","          }, save_file_best)\n","\n","      torch.save({\n","          'epoch': epoch,\n","          'state_dict': regressor.state_dict(),\n","          'last_error': valid_error\n","      }, save_file_last)\n","\n","  print(\"=\" * 120)\n","  print(\"Test best model on test set...\")\n","  checkpoint = torch.load(save_file_best)\n","  regressor.load_state_dict(checkpoint['state_dict'])\n","  print(f\"Loaded best model, epoch {checkpoint['epoch']}, best val error {checkpoint['best_error']:.3f}\")\n","  # test_loss1 = validate_modified(full_loader, model, regressor, \"full\")\n","  # test_loss2 = validate_modified(train_loader, model, regressor, \"train\")\n","  # test_loss3 = validate_modified(val_loader, model, regressor, \"val\")\n","  # test_loss4 = validate_modified(test_loader, model, regressor, \"test\")\n","  test_loss = validate(test_loader, model, regressor)\n","  to_print = 'Test L1 error: {:.3f}'.format(test_loss)\n","  print(to_print)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":219510,"status":"ok","timestamp":1719850203549,"user":{"displayName":"Patrick Do","userId":"05067780781205823530"},"user_tz":240},"id":"5doC7K7ce1LX","outputId":"773763e5-be08-4816-d44c-826843989110"},"outputs":[{"output_type":"stream","name":"stderr","text":["2024-07-01 16:06:23,954 | Model name: Regressor_FruitsDatasetV2_ep_200_lr_0.001_d_0.8_wd_0.0_mmt_0.9_bsz_256_trial_3\n","2024-07-01 16:06:23,956 | Options: Namespace(print_freq=10, save_freq=50, batch_size=256, num_workers=16, epochs=200, learning_rate=0.001, lr_decay_rate=0.8, weight_decay=0.0, momentum=0.9, trial='3', data_folder='./data_fruits_v2', dataset='FruitsDatasetV2', model='resnet18', resume='', aug='crop,flip,rotate', ckpt='save_final/FruitsDatasetV2_models/RnC_FruitsDatasetV2_resnet18_ep_400_lr_0.5_d_0.9_wd_0.0001_mmt_0.9_bsz_256_aug_crop,flip,rotate_temp_2.0_label_l1_feature_l2_trial_0/ckpt_epoch_350.pth', model_name='Regressor_FruitsDatasetV2_ep_200_lr_0.001_d_0.8_wd_0.0_mmt_0.9_bsz_256_trial_3', save_folder='save_final/FruitsDatasetV2_models/RnC_FruitsDatasetV2_resnet18_ep_400_lr_0.5_d_0.9_wd_0.0001_mmt_0.9_bsz_256_aug_crop,flip,rotate_temp_2.0_label_l1_feature_l2_trial_0')\n","2024-07-01 16:06:23,957 | Train Transforms: Compose(\n","    RandomResizedCrop(size=(50, 50), scale=(0.2, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=True)\n","    RandomHorizontalFlip(p=0.5)\n","    RandomRotation(degrees=[-15.0, 15.0], interpolation=nearest, expand=False, fill=0)\n","    Normalize(mean=(0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5))\n",")\n","2024-07-01 16:06:23,959 | Val Transforms: Compose(\n","    Normalize(mean=(0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5))\n",")\n","2024-07-01 16:06:24,104 | Train set size: 1266\tVal set size: 181\tTest set size: 365\n","2024-07-01 16:06:24,428 | <=== Epoch [350] checkpoint Loaded from save_final/FruitsDatasetV2_models/RnC_FruitsDatasetV2_resnet18_ep_400_lr_0.5_d_0.9_wd_0.0001_mmt_0.9_bsz_256_aug_crop,flip,rotate_temp_2.0_label_l1_feature_l2_trial_0/ckpt_epoch_350.pth!\n","2024-07-01 16:06:25,550 | Val L1 error: 0.167\n","2024-07-01 16:06:25,552 | Best Error: 0.167\n","2024-07-01 16:06:26,632 | Val L1 error: 0.121\n","2024-07-01 16:06:26,633 | Best Error: 0.121\n","2024-07-01 16:06:27,685 | Val L1 error: 0.396\n","2024-07-01 16:06:27,686 | Best Error: 0.121\n","2024-07-01 16:06:28,744 | Val L1 error: 0.304\n","2024-07-01 16:06:28,746 | Best Error: 0.121\n","2024-07-01 16:06:29,786 | Val L1 error: 0.346\n","2024-07-01 16:06:29,787 | Best Error: 0.121\n","2024-07-01 16:06:30,817 | Val L1 error: 0.322\n","2024-07-01 16:06:30,818 | Best Error: 0.121\n","2024-07-01 16:06:31,857 | Val L1 error: 0.439\n","2024-07-01 16:06:31,859 | Best Error: 0.121\n","2024-07-01 16:06:32,913 | Val L1 error: 0.177\n","2024-07-01 16:06:32,916 | Best Error: 0.121\n","2024-07-01 16:06:33,943 | Val L1 error: 0.458\n","2024-07-01 16:06:33,945 | Best Error: 0.121\n","2024-07-01 16:06:34,979 | Val L1 error: 0.231\n","2024-07-01 16:06:34,981 | Best Error: 0.121\n","2024-07-01 16:06:36,053 | Val L1 error: 0.370\n","2024-07-01 16:06:36,055 | Best Error: 0.121\n","2024-07-01 16:06:37,131 | Val L1 error: 0.089\n","2024-07-01 16:06:37,134 | Best Error: 0.089\n","2024-07-01 16:06:38,223 | Val L1 error: 0.107\n","2024-07-01 16:06:38,224 | Best Error: 0.089\n","2024-07-01 16:06:39,282 | Val L1 error: 0.367\n","2024-07-01 16:06:39,283 | Best Error: 0.089\n","2024-07-01 16:06:40,331 | Val L1 error: 0.457\n","2024-07-01 16:06:40,333 | Best Error: 0.089\n","2024-07-01 16:06:41,372 | Val L1 error: 0.356\n","2024-07-01 16:06:41,374 | Best Error: 0.089\n","2024-07-01 16:06:42,429 | Val L1 error: 0.250\n","2024-07-01 16:06:42,430 | Best Error: 0.089\n","2024-07-01 16:06:43,481 | Val L1 error: 0.231\n","2024-07-01 16:06:43,483 | Best Error: 0.089\n","2024-07-01 16:06:44,520 | Val L1 error: 0.221\n","2024-07-01 16:06:44,521 | Best Error: 0.089\n","2024-07-01 16:06:45,563 | Val L1 error: 0.306\n","2024-07-01 16:06:45,565 | Best Error: 0.089\n","2024-07-01 16:06:46,616 | Val L1 error: 0.164\n","2024-07-01 16:06:46,617 | Best Error: 0.089\n","2024-07-01 16:06:47,680 | Val L1 error: 0.106\n","2024-07-01 16:06:47,682 | Best Error: 0.089\n","2024-07-01 16:06:48,762 | Val L1 error: 0.257\n","2024-07-01 16:06:48,764 | Best Error: 0.089\n","2024-07-01 16:06:49,850 | Val L1 error: 0.125\n","2024-07-01 16:06:49,852 | Best Error: 0.089\n","2024-07-01 16:06:50,918 | Val L1 error: 0.156\n","2024-07-01 16:06:50,920 | Best Error: 0.089\n","2024-07-01 16:06:51,975 | Val L1 error: 0.190\n","2024-07-01 16:06:51,977 | Best Error: 0.089\n","2024-07-01 16:06:53,023 | Val L1 error: 0.298\n","2024-07-01 16:06:53,025 | Best Error: 0.089\n","2024-07-01 16:06:54,068 | Val L1 error: 0.320\n","2024-07-01 16:06:54,069 | Best Error: 0.089\n","2024-07-01 16:06:55,114 | Val L1 error: 0.132\n","2024-07-01 16:06:55,116 | Best Error: 0.089\n","2024-07-01 16:06:56,164 | Val L1 error: 0.294\n","2024-07-01 16:06:56,166 | Best Error: 0.089\n","2024-07-01 16:06:57,202 | Val L1 error: 0.380\n","2024-07-01 16:06:57,203 | Best Error: 0.089\n","2024-07-01 16:06:58,251 | Val L1 error: 0.088\n","2024-07-01 16:06:58,253 | Best Error: 0.088\n","2024-07-01 16:06:59,306 | Val L1 error: 0.243\n","2024-07-01 16:06:59,307 | Best Error: 0.088\n","2024-07-01 16:07:00,375 | Val L1 error: 0.142\n","2024-07-01 16:07:00,376 | Best Error: 0.088\n","2024-07-01 16:07:01,498 | Val L1 error: 0.163\n","2024-07-01 16:07:01,499 | Best Error: 0.088\n","2024-07-01 16:07:02,610 | Val L1 error: 0.222\n","2024-07-01 16:07:02,611 | Best Error: 0.088\n","2024-07-01 16:07:03,668 | Val L1 error: 0.269\n","2024-07-01 16:07:03,669 | Best Error: 0.088\n","2024-07-01 16:07:04,714 | Val L1 error: 0.121\n","2024-07-01 16:07:04,716 | Best Error: 0.088\n","2024-07-01 16:07:05,750 | Val L1 error: 0.170\n","2024-07-01 16:07:05,752 | Best Error: 0.088\n","2024-07-01 16:07:06,783 | Val L1 error: 0.331\n","2024-07-01 16:07:06,785 | Best Error: 0.088\n","2024-07-01 16:07:07,839 | Val L1 error: 0.129\n","2024-07-01 16:07:07,841 | Best Error: 0.088\n","2024-07-01 16:07:08,892 | Val L1 error: 0.077\n","2024-07-01 16:07:08,894 | Best Error: 0.077\n","2024-07-01 16:07:09,947 | Val L1 error: 0.098\n","2024-07-01 16:07:09,948 | Best Error: 0.077\n","2024-07-01 16:07:11,000 | Val L1 error: 0.170\n","2024-07-01 16:07:11,002 | Best Error: 0.077\n","2024-07-01 16:07:12,057 | Val L1 error: 0.135\n","2024-07-01 16:07:12,059 | Best Error: 0.077\n","2024-07-01 16:07:13,133 | Val L1 error: 0.099\n","2024-07-01 16:07:13,135 | Best Error: 0.077\n","2024-07-01 16:07:14,233 | Val L1 error: 0.070\n","2024-07-01 16:07:14,235 | Best Error: 0.070\n","2024-07-01 16:07:15,320 | Val L1 error: 0.075\n","2024-07-01 16:07:15,321 | Best Error: 0.070\n","2024-07-01 16:07:16,382 | Val L1 error: 0.072\n","2024-07-01 16:07:16,384 | Best Error: 0.070\n","2024-07-01 16:07:17,497 | Val L1 error: 0.088\n","2024-07-01 16:07:17,498 | Best Error: 0.070\n","2024-07-01 16:07:18,547 | Val L1 error: 0.089\n","2024-07-01 16:07:18,549 | Best Error: 0.070\n","2024-07-01 16:07:19,596 | Val L1 error: 0.100\n","2024-07-01 16:07:19,598 | Best Error: 0.070\n","2024-07-01 16:07:20,670 | Val L1 error: 0.082\n","2024-07-01 16:07:20,671 | Best Error: 0.070\n","2024-07-01 16:07:21,727 | Val L1 error: 0.108\n","2024-07-01 16:07:21,729 | Best Error: 0.070\n","2024-07-01 16:07:22,807 | Val L1 error: 0.268\n","2024-07-01 16:07:22,809 | Best Error: 0.070\n","2024-07-01 16:07:23,873 | Val L1 error: 0.066\n","2024-07-01 16:07:23,874 | Best Error: 0.066\n","2024-07-01 16:07:24,924 | Val L1 error: 0.191\n","2024-07-01 16:07:24,930 | Best Error: 0.066\n","2024-07-01 16:07:26,026 | Val L1 error: 0.197\n","2024-07-01 16:07:26,028 | Best Error: 0.066\n","2024-07-01 16:07:27,166 | Val L1 error: 0.241\n","2024-07-01 16:07:27,168 | Best Error: 0.066\n","2024-07-01 16:07:28,218 | Val L1 error: 0.090\n","2024-07-01 16:07:28,220 | Best Error: 0.066\n","2024-07-01 16:07:29,260 | Val L1 error: 0.144\n","2024-07-01 16:07:29,262 | Best Error: 0.066\n","2024-07-01 16:07:30,316 | Val L1 error: 0.189\n","2024-07-01 16:07:30,318 | Best Error: 0.066\n","2024-07-01 16:07:31,387 | Val L1 error: 0.093\n","2024-07-01 16:07:31,388 | Best Error: 0.066\n","2024-07-01 16:07:32,441 | Val L1 error: 0.080\n","2024-07-01 16:07:32,443 | Best Error: 0.066\n","2024-07-01 16:07:33,496 | Val L1 error: 0.081\n","2024-07-01 16:07:33,497 | Best Error: 0.066\n","2024-07-01 16:07:34,531 | Val L1 error: 0.144\n","2024-07-01 16:07:34,533 | Best Error: 0.066\n","2024-07-01 16:07:35,598 | Val L1 error: 0.069\n","2024-07-01 16:07:35,599 | Best Error: 0.066\n","2024-07-01 16:07:36,655 | Val L1 error: 0.088\n","2024-07-01 16:07:36,657 | Best Error: 0.066\n","2024-07-01 16:07:37,760 | Val L1 error: 0.106\n","2024-07-01 16:07:37,762 | Best Error: 0.066\n","2024-07-01 16:07:38,867 | Val L1 error: 0.118\n","2024-07-01 16:07:38,869 | Best Error: 0.066\n","2024-07-01 16:07:39,958 | Val L1 error: 0.082\n","2024-07-01 16:07:39,960 | Best Error: 0.066\n","2024-07-01 16:07:41,017 | Val L1 error: 0.072\n","2024-07-01 16:07:41,018 | Best Error: 0.066\n","2024-07-01 16:07:42,074 | Val L1 error: 0.110\n","2024-07-01 16:07:42,076 | Best Error: 0.066\n","2024-07-01 16:07:43,126 | Val L1 error: 0.111\n","2024-07-01 16:07:43,128 | Best Error: 0.066\n","2024-07-01 16:07:44,190 | Val L1 error: 0.156\n","2024-07-01 16:07:44,192 | Best Error: 0.066\n","2024-07-01 16:07:45,229 | Val L1 error: 0.124\n","2024-07-01 16:07:45,231 | Best Error: 0.066\n","2024-07-01 16:07:46,293 | Val L1 error: 0.235\n","2024-07-01 16:07:46,294 | Best Error: 0.066\n","2024-07-01 16:07:47,350 | Val L1 error: 0.170\n","2024-07-01 16:07:47,352 | Best Error: 0.066\n","2024-07-01 16:07:48,399 | Val L1 error: 0.109\n","2024-07-01 16:07:48,401 | Best Error: 0.066\n","2024-07-01 16:07:49,483 | Val L1 error: 0.096\n","2024-07-01 16:07:49,484 | Best Error: 0.066\n","2024-07-01 16:07:50,572 | Val L1 error: 0.061\n","2024-07-01 16:07:50,574 | Best Error: 0.061\n","2024-07-01 16:07:51,727 | Val L1 error: 0.069\n","2024-07-01 16:07:51,729 | Best Error: 0.061\n","2024-07-01 16:07:52,788 | Val L1 error: 0.088\n","2024-07-01 16:07:52,789 | Best Error: 0.061\n","2024-07-01 16:07:53,838 | Val L1 error: 0.070\n","2024-07-01 16:07:53,840 | Best Error: 0.061\n","2024-07-01 16:07:54,881 | Val L1 error: 0.186\n","2024-07-01 16:07:54,882 | Best Error: 0.061\n","2024-07-01 16:07:55,938 | Val L1 error: 0.134\n","2024-07-01 16:07:55,940 | Best Error: 0.061\n","2024-07-01 16:07:57,007 | Val L1 error: 0.173\n","2024-07-01 16:07:57,009 | Best Error: 0.061\n","2024-07-01 16:07:58,043 | Val L1 error: 0.073\n","2024-07-01 16:07:58,044 | Best Error: 0.061\n","2024-07-01 16:07:59,097 | Val L1 error: 0.211\n","2024-07-01 16:07:59,098 | Best Error: 0.061\n","2024-07-01 16:08:00,171 | Val L1 error: 0.074\n","2024-07-01 16:08:00,172 | Best Error: 0.061\n","2024-07-01 16:08:01,225 | Val L1 error: 0.082\n","2024-07-01 16:08:01,226 | Best Error: 0.061\n","2024-07-01 16:08:02,317 | Val L1 error: 0.100\n","2024-07-01 16:08:02,319 | Best Error: 0.061\n","2024-07-01 16:08:03,436 | Val L1 error: 0.152\n","2024-07-01 16:08:03,438 | Best Error: 0.061\n","2024-07-01 16:08:04,520 | Val L1 error: 0.074\n","2024-07-01 16:08:04,521 | Best Error: 0.061\n","2024-07-01 16:08:05,568 | Val L1 error: 0.087\n","2024-07-01 16:08:05,570 | Best Error: 0.061\n","2024-07-01 16:08:06,629 | Val L1 error: 0.101\n","2024-07-01 16:08:06,630 | Best Error: 0.061\n","2024-07-01 16:08:07,708 | Val L1 error: 0.131\n","2024-07-01 16:08:07,710 | Best Error: 0.061\n","2024-07-01 16:08:08,786 | Val L1 error: 0.162\n","2024-07-01 16:08:08,788 | Best Error: 0.061\n","2024-07-01 16:08:09,844 | Val L1 error: 0.091\n","2024-07-01 16:08:09,846 | Best Error: 0.061\n","2024-07-01 16:08:10,904 | Val L1 error: 0.087\n","2024-07-01 16:08:10,907 | Best Error: 0.061\n","2024-07-01 16:08:11,957 | Val L1 error: 0.082\n","2024-07-01 16:08:11,958 | Best Error: 0.061\n","2024-07-01 16:08:13,018 | Val L1 error: 0.068\n","2024-07-01 16:08:13,019 | Best Error: 0.061\n","2024-07-01 16:08:14,119 | Val L1 error: 0.064\n","2024-07-01 16:08:14,121 | Best Error: 0.061\n","2024-07-01 16:08:15,222 | Val L1 error: 0.066\n","2024-07-01 16:08:15,224 | Best Error: 0.061\n","2024-07-01 16:08:16,334 | Val L1 error: 0.086\n","2024-07-01 16:08:16,336 | Best Error: 0.061\n","2024-07-01 16:08:17,391 | Val L1 error: 0.071\n","2024-07-01 16:08:17,393 | Best Error: 0.061\n","2024-07-01 16:08:18,458 | Val L1 error: 0.102\n","2024-07-01 16:08:18,460 | Best Error: 0.061\n","2024-07-01 16:08:19,582 | Val L1 error: 0.072\n","2024-07-01 16:08:19,583 | Best Error: 0.061\n","2024-07-01 16:08:20,647 | Val L1 error: 0.076\n","2024-07-01 16:08:20,649 | Best Error: 0.061\n","2024-07-01 16:08:21,721 | Val L1 error: 0.092\n","2024-07-01 16:08:21,722 | Best Error: 0.061\n","2024-07-01 16:08:22,794 | Val L1 error: 0.060\n","2024-07-01 16:08:22,796 | Best Error: 0.060\n","2024-07-01 16:08:23,908 | Val L1 error: 0.064\n","2024-07-01 16:08:23,909 | Best Error: 0.060\n","2024-07-01 16:08:25,013 | Val L1 error: 0.073\n","2024-07-01 16:08:25,015 | Best Error: 0.060\n","2024-07-01 16:08:26,072 | Val L1 error: 0.075\n","2024-07-01 16:08:26,074 | Best Error: 0.060\n","2024-07-01 16:08:27,353 | Val L1 error: 0.073\n","2024-07-01 16:08:27,354 | Best Error: 0.060\n","2024-07-01 16:08:28,485 | Val L1 error: 0.133\n","2024-07-01 16:08:28,487 | Best Error: 0.060\n","2024-07-01 16:08:29,558 | Val L1 error: 0.226\n","2024-07-01 16:08:29,560 | Best Error: 0.060\n","2024-07-01 16:08:30,674 | Val L1 error: 0.221\n","2024-07-01 16:08:30,676 | Best Error: 0.060\n","2024-07-01 16:08:31,778 | Val L1 error: 0.205\n","2024-07-01 16:08:31,780 | Best Error: 0.060\n","2024-07-01 16:08:32,851 | Val L1 error: 0.062\n","2024-07-01 16:08:32,852 | Best Error: 0.060\n","2024-07-01 16:08:33,923 | Val L1 error: 0.113\n","2024-07-01 16:08:33,926 | Best Error: 0.060\n","2024-07-01 16:08:34,995 | Val L1 error: 0.104\n","2024-07-01 16:08:34,997 | Best Error: 0.060\n","2024-07-01 16:08:36,077 | Val L1 error: 0.096\n","2024-07-01 16:08:36,079 | Best Error: 0.060\n","2024-07-01 16:08:37,211 | Val L1 error: 0.075\n","2024-07-01 16:08:37,213 | Best Error: 0.060\n","2024-07-01 16:08:38,327 | Val L1 error: 0.081\n","2024-07-01 16:08:38,329 | Best Error: 0.060\n","2024-07-01 16:08:39,461 | Val L1 error: 0.071\n","2024-07-01 16:08:39,462 | Best Error: 0.060\n","2024-07-01 16:08:40,672 | Val L1 error: 0.061\n","2024-07-01 16:08:40,674 | Best Error: 0.060\n","2024-07-01 16:08:41,768 | Val L1 error: 0.065\n","2024-07-01 16:08:41,770 | Best Error: 0.060\n","2024-07-01 16:08:42,854 | Val L1 error: 0.063\n","2024-07-01 16:08:42,856 | Best Error: 0.060\n","2024-07-01 16:08:43,965 | Val L1 error: 0.075\n","2024-07-01 16:08:43,967 | Best Error: 0.060\n","2024-07-01 16:08:45,067 | Val L1 error: 0.086\n","2024-07-01 16:08:45,069 | Best Error: 0.060\n","2024-07-01 16:08:46,182 | Val L1 error: 0.071\n","2024-07-01 16:08:46,184 | Best Error: 0.060\n","2024-07-01 16:08:47,298 | Val L1 error: 0.061\n","2024-07-01 16:08:47,300 | Best Error: 0.060\n","2024-07-01 16:08:48,424 | Val L1 error: 0.083\n","2024-07-01 16:08:48,425 | Best Error: 0.060\n","2024-07-01 16:08:49,555 | Val L1 error: 0.100\n","2024-07-01 16:08:49,557 | Best Error: 0.060\n","2024-07-01 16:08:50,655 | Val L1 error: 0.106\n","2024-07-01 16:08:50,656 | Best Error: 0.060\n","2024-07-01 16:08:51,799 | Val L1 error: 0.062\n","2024-07-01 16:08:51,801 | Best Error: 0.060\n","2024-07-01 16:08:52,971 | Val L1 error: 0.075\n","2024-07-01 16:08:52,973 | Best Error: 0.060\n","2024-07-01 16:08:54,074 | Val L1 error: 0.109\n","2024-07-01 16:08:54,076 | Best Error: 0.060\n","2024-07-01 16:08:55,167 | Val L1 error: 0.077\n","2024-07-01 16:08:55,169 | Best Error: 0.060\n","2024-07-01 16:08:56,272 | Val L1 error: 0.061\n","2024-07-01 16:08:56,273 | Best Error: 0.060\n","2024-07-01 16:08:57,363 | Val L1 error: 0.151\n","2024-07-01 16:08:57,365 | Best Error: 0.060\n","2024-07-01 16:08:58,464 | Val L1 error: 0.123\n","2024-07-01 16:08:58,465 | Best Error: 0.060\n","2024-07-01 16:08:59,557 | Val L1 error: 0.146\n","2024-07-01 16:08:59,559 | Best Error: 0.060\n","2024-07-01 16:09:00,657 | Val L1 error: 0.196\n","2024-07-01 16:09:00,658 | Best Error: 0.060\n","2024-07-01 16:09:01,770 | Val L1 error: 0.140\n","2024-07-01 16:09:01,772 | Best Error: 0.060\n","2024-07-01 16:09:02,857 | Val L1 error: 0.064\n","2024-07-01 16:09:02,859 | Best Error: 0.060\n","2024-07-01 16:09:04,021 | Val L1 error: 0.074\n","2024-07-01 16:09:04,023 | Best Error: 0.060\n","2024-07-01 16:09:05,164 | Val L1 error: 0.061\n","2024-07-01 16:09:05,166 | Best Error: 0.060\n","2024-07-01 16:09:06,265 | Val L1 error: 0.060\n","2024-07-01 16:09:06,266 | Best Error: 0.060\n","2024-07-01 16:09:07,335 | Val L1 error: 0.068\n","2024-07-01 16:09:07,337 | Best Error: 0.060\n","2024-07-01 16:09:08,432 | Val L1 error: 0.064\n","2024-07-01 16:09:08,434 | Best Error: 0.060\n","2024-07-01 16:09:09,529 | Val L1 error: 0.077\n","2024-07-01 16:09:09,531 | Best Error: 0.060\n","2024-07-01 16:09:10,602 | Val L1 error: 0.076\n","2024-07-01 16:09:10,604 | Best Error: 0.060\n","2024-07-01 16:09:11,716 | Val L1 error: 0.067\n","2024-07-01 16:09:11,718 | Best Error: 0.060\n","2024-07-01 16:09:12,820 | Val L1 error: 0.063\n","2024-07-01 16:09:12,821 | Best Error: 0.060\n","2024-07-01 16:09:13,945 | Val L1 error: 0.060\n","2024-07-01 16:09:13,947 | Best Error: 0.060\n","2024-07-01 16:09:15,059 | Val L1 error: 0.066\n","2024-07-01 16:09:15,061 | Best Error: 0.060\n","2024-07-01 16:09:16,228 | Val L1 error: 0.059\n","2024-07-01 16:09:16,231 | Best Error: 0.059\n","2024-07-01 16:09:17,399 | Val L1 error: 0.060\n","2024-07-01 16:09:17,401 | Best Error: 0.059\n","2024-07-01 16:09:18,502 | Val L1 error: 0.063\n","2024-07-01 16:09:18,504 | Best Error: 0.059\n","2024-07-01 16:09:19,612 | Val L1 error: 0.088\n","2024-07-01 16:09:19,614 | Best Error: 0.059\n","2024-07-01 16:09:20,747 | Val L1 error: 0.061\n","2024-07-01 16:09:20,748 | Best Error: 0.059\n","2024-07-01 16:09:21,878 | Val L1 error: 0.064\n","2024-07-01 16:09:21,880 | Best Error: 0.059\n","2024-07-01 16:09:22,994 | Val L1 error: 0.059\n","2024-07-01 16:09:22,995 | Best Error: 0.059\n","2024-07-01 16:09:24,089 | Val L1 error: 0.059\n","2024-07-01 16:09:24,091 | Best Error: 0.059\n","2024-07-01 16:09:25,223 | Val L1 error: 0.061\n","2024-07-01 16:09:25,225 | Best Error: 0.059\n","2024-07-01 16:09:26,334 | Val L1 error: 0.059\n","2024-07-01 16:09:26,336 | Best Error: 0.059\n","2024-07-01 16:09:27,484 | Val L1 error: 0.065\n","2024-07-01 16:09:27,486 | Best Error: 0.059\n","2024-07-01 16:09:28,639 | Val L1 error: 0.090\n","2024-07-01 16:09:28,641 | Best Error: 0.059\n","2024-07-01 16:09:29,825 | Val L1 error: 0.062\n","2024-07-01 16:09:29,827 | Best Error: 0.059\n","2024-07-01 16:09:30,932 | Val L1 error: 0.060\n","2024-07-01 16:09:30,934 | Best Error: 0.059\n","2024-07-01 16:09:32,044 | Val L1 error: 0.059\n","2024-07-01 16:09:32,046 | Best Error: 0.059\n","2024-07-01 16:09:33,181 | Val L1 error: 0.061\n","2024-07-01 16:09:33,183 | Best Error: 0.059\n","2024-07-01 16:09:34,284 | Val L1 error: 0.061\n","2024-07-01 16:09:34,286 | Best Error: 0.059\n","2024-07-01 16:09:35,388 | Val L1 error: 0.065\n","2024-07-01 16:09:35,390 | Best Error: 0.059\n","2024-07-01 16:09:36,505 | Val L1 error: 0.066\n","2024-07-01 16:09:36,506 | Best Error: 0.059\n","2024-07-01 16:09:37,619 | Val L1 error: 0.072\n","2024-07-01 16:09:37,621 | Best Error: 0.059\n","2024-07-01 16:09:38,744 | Val L1 error: 0.068\n","2024-07-01 16:09:38,746 | Best Error: 0.059\n","2024-07-01 16:09:39,884 | Val L1 error: 0.100\n","2024-07-01 16:09:39,885 | Best Error: 0.059\n","2024-07-01 16:09:41,052 | Val L1 error: 0.067\n","2024-07-01 16:09:41,054 | Best Error: 0.059\n","2024-07-01 16:09:42,249 | Val L1 error: 0.073\n","2024-07-01 16:09:42,251 | Best Error: 0.059\n","2024-07-01 16:09:43,367 | Val L1 error: 0.087\n","2024-07-01 16:09:43,369 | Best Error: 0.059\n","2024-07-01 16:09:44,480 | Val L1 error: 0.103\n","2024-07-01 16:09:44,482 | Best Error: 0.059\n","2024-07-01 16:09:45,568 | Val L1 error: 0.107\n","2024-07-01 16:09:45,570 | Best Error: 0.059\n","2024-07-01 16:09:46,711 | Val L1 error: 0.080\n","2024-07-01 16:09:46,712 | Best Error: 0.059\n","2024-07-01 16:09:47,848 | Val L1 error: 0.076\n","2024-07-01 16:09:47,850 | Best Error: 0.059\n","2024-07-01 16:09:48,985 | Val L1 error: 0.058\n","2024-07-01 16:09:48,986 | Best Error: 0.058\n","2024-07-01 16:09:50,113 | Val L1 error: 0.073\n","2024-07-01 16:09:50,115 | Best Error: 0.058\n","2024-07-01 16:09:51,247 | Val L1 error: 0.094\n","2024-07-01 16:09:51,249 | Best Error: 0.058\n","2024-07-01 16:09:52,372 | Val L1 error: 0.090\n","2024-07-01 16:09:52,374 | Best Error: 0.058\n","2024-07-01 16:09:53,510 | Val L1 error: 0.086\n","2024-07-01 16:09:53,515 | Best Error: 0.058\n","2024-07-01 16:09:54,692 | Val L1 error: 0.093\n","2024-07-01 16:09:54,694 | Best Error: 0.058\n","2024-07-01 16:09:55,816 | Val L1 error: 0.059\n","2024-07-01 16:09:55,818 | Best Error: 0.058\n","2024-07-01 16:09:56,933 | Val L1 error: 0.085\n","2024-07-01 16:09:56,935 | Best Error: 0.058\n","2024-07-01 16:09:58,025 | Val L1 error: 0.064\n","2024-07-01 16:09:58,026 | Best Error: 0.058\n","2024-07-01 16:09:59,113 | Val L1 error: 0.060\n","2024-07-01 16:09:59,115 | Best Error: 0.058\n","2024-07-01 16:10:00,237 | Val L1 error: 0.082\n","2024-07-01 16:10:00,239 | Best Error: 0.058\n","2024-07-01 16:10:01,367 | Val L1 error: 0.072\n","2024-07-01 16:10:01,368 | Best Error: 0.058\n","2024-07-01 16:10:02,490 | Val L1 error: 0.061\n","2024-07-01 16:10:02,492 | Best Error: 0.058\n","2024-07-01 16:10:02,499 | ========================================================================================================================\n","2024-07-01 16:10:02,500 | Test best model on test set...\n","2024-07-01 16:10:02,505 | Loaded best model, epoch 188, best val error 0.058\n","2024-07-01 16:10:02,904 | Test L1 error: 0.064\n"]}],"source":["args = [\n","    '--print_freq', '10',\n","    '--save_freq', '50',\n","\n","    '--batch_size', '256',\n","    '--num_workers', '16',\n","    '--epochs', '200',\n","    '--learning_rate', '0.001',\n","    '--lr_decay_rate', '0.8',\n","    '--weight_decay', '0',\n","    '--momentum', '0.9',\n","    '--trial', '3',\n","\n","    '--data_folder', './data_fruits_v2',\n","    '--dataset', 'FruitsDatasetV2',\n","    '--model', 'resnet18',\n","    '--resume', '',\n","    '--aug', 'crop,flip,rotate',\n","\n","    # '--ckpt', 'save/FruitsDatasetRGB_models/RnC_FruitsDatasetRGB_resnet18_ep_400_lr_0.5_d_0.9_wd_0.0001_mmt_0.9_bsz_256_aug_crop,flip,rotate_temp_2.0_label_l1_feature_l2_trial_0/last.pth'\n","    # '--ckpt', 'save/FruitsDataset30C_models/RnC_FruitsDataset30C_resnet18_ep_400_lr_0.5_d_0.9_wd_0.0001_mmt_0.9_bsz_256_aug_crop,flip,rotate_temp_2.0_label_l1_feature_l2_trial_0/last.pth'\n","    '--ckpt', 'save_final/FruitsDatasetV2_models/RnC_FruitsDatasetV2_resnet18_ep_400_lr_0.5_d_0.9_wd_0.0001_mmt_0.9_bsz_256_aug_crop,flip,rotate_temp_2.0_label_l1_feature_l2_trial_0/ckpt_epoch_350.pth'\n","]\n","\n","main_linear(args, num_channel=8)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}