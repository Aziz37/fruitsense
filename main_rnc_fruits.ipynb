{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"L4","machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bXWFsgseLavO","executionInfo":{"status":"ok","timestamp":1719800187935,"user_tz":240,"elapsed":80254,"user":{"displayName":"Patrick Do","userId":"05067780781205823530"}},"outputId":"35cdda2f-520e-468b-ab48-84d5731e42df"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd '/content/drive/My Drive/Fruit_States_RnC'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-VRO5SqML5Ti","executionInfo":{"status":"ok","timestamp":1719800187935,"user_tz":240,"elapsed":4,"user":{"displayName":"Patrick Do","userId":"05067780781205823530"}},"outputId":"87fc7e98-7001-4bce-9e6e-568bba2aeeaa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1bNsY41NQ7yt_0gKqP3j-2gJ1pdli4usp/Fruit_States_RnC\n"]}]},{"cell_type":"code","source":["import argparse\n","import os\n","import sys\n","import logging\n","import torch\n","import time\n","from dataset_fruits import *\n","from utils_fruits import *\n","from model_fruits import Encoder\n","from loss import RnCLoss"],"metadata":{"id":"Graz9u0SLA35"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print = logging.info"],"metadata":{"id":"I9lTXuosLJoZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def parse_option(args=None):\n","    parser = argparse.ArgumentParser('argument for training')\n","\n","    parser.add_argument('--print_freq', type=int, default=10, help='print frequency')\n","    parser.add_argument('--save_freq', type=int, default=50, help='save frequency')\n","    parser.add_argument('--save_curr_freq', type=int, default=1, help='save curr last frequency')\n","\n","    parser.add_argument('--batch_size', type=int, default=256, help='batch_size')\n","    parser.add_argument('--num_workers', type=int, default=16, help='num of workers to use')\n","    parser.add_argument('--epochs', type=int, default=400, help='number of training epochs')\n","    parser.add_argument('--learning_rate', type=float, default=0.5, help='learning rate')\n","    parser.add_argument('--lr_decay_rate', type=float, default=0.1, help='decay rate for learning rate')\n","    parser.add_argument('--weight_decay', type=float, default=1e-4, help='weight decay')\n","    parser.add_argument('--momentum', type=float, default=0.9, help='momentum')\n","    parser.add_argument('--trial', type=str, default='0', help='id for recording multiple runs')\n","\n","    parser.add_argument('--data_folder', type=str, default='./data_fruits', help='path to custom dataset')\n","    parser.add_argument('--dataset', type=str, default='FruitsDataset', choices=['FruitsDataset','FruitsDatasetV2', 'FruitsDatasetRGB', 'FruitsDataset30C'], help='dataset')\n","    parser.add_argument('--model', type=str, default='resnet18', choices=['resnet18', 'resnet50'])\n","    parser.add_argument('--resume', type=str, default='', help='resume ckpt path')\n","    parser.add_argument('--aug', type=str, default='crop,flip,rotate', help='augmentations')\n","\n","    # RnCLoss Parameters\n","    parser.add_argument('--temp', type=float, default=2, help='temperature')\n","    parser.add_argument('--label_diff', type=str, default='l1', choices=['l1'], help='label distance function')\n","    parser.add_argument('--feature_sim', type=str, default='l2', choices=['l2'], help='feature similarity function')\n","\n","    if args is None:\n","        args = []\n","    opt = parser.parse_args(args=args)\n","\n","    opt.model_path = './save/{}_models'.format(opt.dataset)\n","    opt.model_name = 'RnC_{}_{}_ep_{}_lr_{}_d_{}_wd_{}_mmt_{}_bsz_{}_aug_{}_temp_{}_label_{}_feature_{}_trial_{}'. \\\n","        format(opt.dataset, opt.model, opt.epochs, opt.learning_rate, opt.lr_decay_rate, opt.weight_decay, opt.momentum,\n","               opt.batch_size, opt.aug, opt.temp, opt.label_diff, opt.feature_sim, opt.trial)\n","    if len(opt.resume):\n","        opt.model_name = opt.resume.split('/')[-2]\n","\n","    opt.save_folder = os.path.join(opt.model_path, opt.model_name)\n","    if not os.path.isdir(opt.save_folder):\n","        os.makedirs(opt.save_folder)\n","    else:\n","        print('WARNING: folder exist.')\n","\n","    logging.root.handlers = []\n","    logging.basicConfig(\n","        level=logging.INFO,\n","        format=\"%(asctime)s | %(message)s\",\n","        handlers=[\n","            logging.FileHandler(os.path.join(opt.save_folder, 'training.log')),\n","            logging.StreamHandler()\n","        ])\n","\n","    print(f\"Model name: {opt.model_name}\")\n","    print(f\"Options: {opt}\")\n","\n","    return opt"],"metadata":{"id":"-hu8Cs-TLNUk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def set_loader(opt, num_channel=3):\n","    train_transform = get_transforms(split='train', aug=opt.aug, num_channel=num_channel)\n","    print(f\"Train Transforms: {train_transform}\")\n","\n","    train_dataset = globals()[opt.dataset](\n","        data_folder=opt.data_folder,\n","        transform=TwoCropTransform(train_transform),\n","        split='train'\n","    )\n","    print(f'Train set size: {train_dataset.__len__()}')\n","\n","    train_loader = torch.utils.data.DataLoader(\n","        train_dataset, batch_size=opt.batch_size, shuffle=True,\n","        num_workers=opt.num_workers, pin_memory=True, drop_last=True)\n","\n","\n","    return train_loader\n","\n","def set_model(opt, num_channel=3):\n","    model = Encoder(name=opt.model, in_channel=num_channel)\n","    # criterion = RnCLoss(temperature=opt.temp, label_diff=opt.label_diff, feature_sim=opt.feature_sim)\n","    criterion = torch.nn.L1Loss()\n","\n","    if torch.cuda.is_available():\n","        if torch.cuda.device_count() > 1:\n","            model.encoder = torch.nn.DataParallel(model.encoder)\n","        model = model.cuda()\n","        criterion = criterion.cuda()\n","        torch.backends.cudnn.benchmark = True\n","\n","    return model, criterion\n","\n","\n","def train(train_loader, model, criterion, optimizer, epoch, opt):\n","    model.train()\n","\n","    batch_time = AverageMeter()\n","    data_time = AverageMeter()\n","    losses = AverageMeter()\n","\n","    end = time.time()\n","    for idx, data_tuple in enumerate(train_loader):\n","        images, labels = data_tuple\n","        data_time.update(time.time() - end)\n","        bsz = labels.shape[0]\n","        images = torch.cat([images[0], images[1]], dim=0)\n","\n","        if torch.cuda.is_available():\n","            images = images.cuda(non_blocking=True)\n","            labels = labels.cuda(non_blocking=True)\n","\n","        features = model(images)\n","        f1, f2 = torch.split(features, [bsz, bsz], dim=0)\n","        features = torch.cat([f1.unsqueeze(1), f2.unsqueeze(1)], dim=1)\n","\n","        ####\n","        labels = labels.unsqueeze(1).expand(-1, 2, -1)\n","\n","        # print(features.shape)\n","        # print(labels.shape)\n","        loss = criterion(features, labels)\n","        losses.update(loss.item(), bsz)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","\n","        if (idx + 1) % opt.print_freq == 0:\n","            to_print = 'Train: [{0}][{1}/{2}]\\t' \\\n","                       'BT {batch_time.val:.3f} ({batch_time.avg:.3f})\\t' \\\n","                       'DT {data_time.val:.3f} ({data_time.avg:.3f})\\t' \\\n","                       'loss {loss.val:.5f} ({loss.avg:.5f})'.format(\n","                epoch, idx + 1, len(train_loader), batch_time=batch_time,\n","                data_time=data_time, loss=losses\n","            )\n","            print(to_print)\n","            sys.stdout.flush()"],"metadata":{"id":"cAqrhsh8LS2A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def main_rnc_fruits(args=None, num_channel=8):\n","    opt = parse_option(args)\n","\n","    # build data loader\n","    train_loader = set_loader(opt, num_channel=num_channel)\n","\n","    # build model and criterion\n","    model, criterion = set_model(opt, num_channel=num_channel)\n","\n","    # build optimizer\n","    optimizer = set_optimizer(opt, model)\n","\n","    start_epoch = 1\n","    if len(opt.resume):\n","        ckpt_state = torch.load(opt.resume)\n","        model.load_state_dict(ckpt_state['model'])\n","        optimizer.load_state_dict(ckpt_state['optimizer'])\n","        start_epoch = ckpt_state['epoch'] + 1\n","        print(f\"<=== Epoch [{ckpt_state['epoch']}] Resumed from {opt.resume}!\")\n","\n","    # training routine\n","    for epoch in range(start_epoch, opt.epochs + 1):\n","        adjust_learning_rate(opt, optimizer, epoch)\n","\n","        train(train_loader, model, criterion, optimizer, epoch, opt)\n","\n","        if epoch % opt.save_freq == 0:\n","            save_file = os.path.join(\n","                opt.save_folder, 'ckpt_epoch_{epoch}.pth'.format(epoch=epoch))\n","            save_model(model, optimizer, opt, epoch, save_file)\n","\n","        if epoch % opt.save_curr_freq == 0:\n","            save_file = os.path.join(opt.save_folder, 'curr_last.pth')\n","            save_model(model, optimizer, opt, epoch, save_file)\n","\n","    # save the last model\n","    save_file = os.path.join(opt.save_folder, 'last.pth')\n","    save_model(model, optimizer, opt, opt.epochs, save_file)"],"metadata":{"id":"TvbwPujlLWZJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["args = [\n","    '--print_freq', '10',\n","    '--save_freq', '50',\n","    '--save_curr_freq', '1',\n","\n","    '--batch_size', '256',\n","    '--num_workers', '16',\n","    '--epochs', '400',\n","    '--learning_rate', '0.5',\n","    '--lr_decay_rate', '0.9',\n","    '--weight_decay', '1e-4',\n","    '--momentum','0.9',\n","    '--trial', '0',\n","\n","    '--data_folder', './data_fruits_v2',\n","    '--dataset', 'FruitsDatasetRGB',\n","    '--model', 'resnet18',\n","    '--resume', '',\n","    '--aug', 'crop,flip,rotate',\n","\n","    '--temp', '2',\n","    '--label_diff', 'l1',\n","    '--feature_sim', 'l2'\n","]"],"metadata":{"id":"c89CTFB3KmIf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["main_rnc_fruits(args, num_channel=3)"],"metadata":{"id":"tSre_DIdKzG8","colab":{"base_uri":"https://localhost:8080/"},"outputId":"861c20f6-e10f-4923-fc0e-2aa84ef82f2e","executionInfo":{"status":"ok","timestamp":1719800729111,"user_tz":240,"elapsed":532183,"user":{"displayName":"Patrick Do","userId":"05067780781205823530"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2024-07-01 02:16:36,196 | Model name: RnC_FruitsDatasetRGB_resnet18_ep_400_lr_0.5_d_0.9_wd_0.0001_mmt_0.9_bsz_256_aug_crop,flip,rotate_temp_2.0_label_l1_feature_l2_trial_0\n","2024-07-01 02:16:36,198 | Options: Namespace(print_freq=10, save_freq=50, save_curr_freq=1, batch_size=256, num_workers=16, epochs=400, learning_rate=0.5, lr_decay_rate=0.9, weight_decay=0.0001, momentum=0.9, trial='0', data_folder='./data_fruits_v2', dataset='FruitsDatasetRGB', model='resnet18', resume='', aug='crop,flip,rotate', temp=2.0, label_diff='l1', feature_sim='l2', model_path='./save/FruitsDatasetRGB_models', model_name='RnC_FruitsDatasetRGB_resnet18_ep_400_lr_0.5_d_0.9_wd_0.0001_mmt_0.9_bsz_256_aug_crop,flip,rotate_temp_2.0_label_l1_feature_l2_trial_0', save_folder='./save/FruitsDatasetRGB_models/RnC_FruitsDatasetRGB_resnet18_ep_400_lr_0.5_d_0.9_wd_0.0001_mmt_0.9_bsz_256_aug_crop,flip,rotate_temp_2.0_label_l1_feature_l2_trial_0')\n","2024-07-01 02:16:36,199 | Train Transforms: Compose(\n","    RandomResizedCrop(size=(50, 50), scale=(0.2, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=True)\n","    RandomHorizontalFlip(p=0.5)\n","    RandomRotation(degrees=[-15.0, 15.0], interpolation=nearest, expand=False, fill=0)\n","    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",")\n","2024-07-01 02:16:42,128 | Train set size: 1266\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([256, 2, 1])) that is different to the input size (torch.Size([256, 2, 512])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.l1_loss(input, target, reduction=self.reduction)\n"]},{"output_type":"stream","name":"stdout","text":["==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n","==> Saving...\n"]}]}]}